{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РАССТОЯНИЕ ЛЕВЕНШТЕЙНА И КЛАСТЕРИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "\n",
    "class clustering_Lev_kmeans:\n",
    "    \n",
    "    \n",
    "    def read_data(filename):\n",
    "        with open(filename, 'rt') as csvfile:\n",
    "            data = list(csv.reader(csvfile))\n",
    "            data.pop(0)\n",
    "            return data\n",
    "    \n",
    "    def max_dim(data, use_chars=False):\n",
    "        max = 0 \n",
    "        if use_chars:\n",
    "            for dataset in data:\n",
    "                if len(dataset[0]) > max:\n",
    "                    max = len(dataset[0])\n",
    "        else:\n",
    "            for dataset in data:\n",
    "                if len(dataset) > max:\n",
    "                    max = len(dataset)\n",
    "        return max\n",
    "    \n",
    "    def convert_with_dictionary(data, dictionary):\n",
    "        for dataset in data:\n",
    "            for i in range(len(dataset)):\n",
    "                dataset[i] = dictionary[dataset[i]]\n",
    "    \n",
    "    def get_unique_words(data):\n",
    "        unique_words = set()    \n",
    "        for datasets in data:\n",
    "            for datapoint in datasets:\n",
    "                unique_words.add(datapoint)\n",
    "    \n",
    "        return list(unique_words)    \n",
    "\n",
    "    def create_dicts(data, use_chars=False):   \n",
    "        unique_words = get_unique_words(data)\n",
    "        if use_chars == True:\n",
    "            datapoint2char = {}\n",
    "            char2datapoint = {}\n",
    "            char = string.ascii_lowercase[0]\n",
    "            for datapoint in unique_words:\n",
    "                datapoint2char[datapoint] = char\n",
    "                char2datapoint[char] = datapoint\n",
    "                char = chr(ord(char) + 1) \n",
    "            return datapoint2char, char2datapoint\n",
    "        else:\n",
    "            datapoint2num = {}\n",
    "            num2datapoint = {}\n",
    "            num = 5\n",
    "            for datapoint in unique_words:\n",
    "                datapoint2num[datapoint] = num\n",
    "                num2datapoint[num] = datapoint\n",
    "                num = num+1\n",
    "            return datapoint2num, num2datapoint\n",
    "    \n",
    "    def join_chars(data):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = [''.join(data[i])]\n",
    "        return data\n",
    "    \n",
    "    def split_chars(data):\n",
    "        for i in range(len(data)):\n",
    "            data[i] = list(data[i])\n",
    "        return data\n",
    "    \n",
    "\n",
    "    def plot_data(data):    \n",
    "        index = 0\n",
    "        for dataset in data:\n",
    "            plt.plot(dataset)\n",
    "            index = index+1\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def euclidean_distance(a, b):\n",
    "        dist = 0\n",
    "        if len(a) < len(b):\n",
    "            a,b = b,a\n",
    "        for i in range(len(a)):\n",
    "            if i < len(b):\n",
    "                dist = dist + (a[i] - b[i]) ** 2\n",
    "            else:\n",
    "                dist = dist + a[i]**2\n",
    "        return math.sqrt(dist)\n",
    "    \n",
    "    def levenshtein_on_numbers(dataset1, dataset2):\n",
    "        datapoint2char, char2datapoint = create_dicts([dataset1, dataset2], use_chars=True)        \n",
    "        convert_with_dictionary([dataset1], datapoint2char)\n",
    "        convert_with_dictionary([dataset2], datapoint2char)\n",
    "        join_chars([dataset1])\n",
    "        join_chars([dataset2])\n",
    "        distance = d_levenshtein_distance(dataset1, dataset2) \n",
    "        split_chars([dataset1])\n",
    "        split_chars([dataset2]) \n",
    "        convert_with_dictionary([dataset1], char2datapoint)\n",
    "        convert_with_dictionary([dataset2], char2datapoint)  \n",
    "        return distance\n",
    "               \n",
    "    def d_levenshtein_distance(str1, str2):\n",
    "        d = {}\n",
    "        for i in range(len(str1) + 1):\n",
    "            d[(i,0)] = i\n",
    "        for j in range(len(str2) + 1):\n",
    "            d[(0,j)] = j\n",
    "        for i in range(1, len(str1) + 1):\n",
    "            for j in range(1, len(str2) + 1):\n",
    "                if str1[i-1] == str2[j-1]:\n",
    "                    subst_or_equal = d[(i-1, j-1)] + 0\n",
    "                else:\n",
    "                    subst_or_equal = d[(i-1, j-1)] + 1\n",
    "                deletion = d[(i-1,j)] + 1\n",
    "                insertion = d[(i,j-1)] + 1\n",
    "                if (i >= 2 and j >= 2) and (str1[i-1] == str2[j-2] and str1[i-2] == str2[j-1]):\n",
    "                    switch = d[(i-2,j-2)] + 1\n",
    "                    d[(i,j)] = min(subst_or_equal, deletion, insertion, switch)\n",
    "                else:\n",
    "                    d[(i,j)] = min(subst_or_equal, deletion, insertion)\n",
    "        return d[(len(str1), len(str2))]\n",
    "    \n",
    "    def dtw_distance(dataset1, dataset2):\n",
    "        dtw = {}\n",
    "        for i in range(len(dataset1)):\n",
    "            dtw[(i,-1)] = float('inf')\n",
    "        for i in range(len(dataset2)):\n",
    "            dtw[(-1,i)] = float('inf')\n",
    "        dtw[(-1,-1)] = 0\n",
    "        for i in range(len(dataset1)):\n",
    "            for j in range(len(dataset2)):\n",
    "                dist = (dataset1[i] - dataset2[j])**2\n",
    "                dtw[(i,j)] = dist + min(dtw[(i-1,j)], dtw[(i,j-1)], dtw[(i-1,j-1)]) \n",
    "        return math.sqrt(dtw[len(dataset1)-1, len(dataset2)-1])\n",
    "    \n",
    "    def k_means(k, data, dist_fun):\n",
    "        centroids = []\n",
    "        old_centroids = []\n",
    "        cluster_for_dataset = []\n",
    "        clusters = [[] for i in range(k)]\n",
    "        delta_centroid_sum = 0\n",
    "        dataset_dim = max_dim(data)\n",
    "        min_value = 2\n",
    "        c = list([datapoint for dataset in data for datapoint in dataset])\n",
    "        c.sort()\n",
    "        max_value =  c[-1]\n",
    "        zeros = [0 for i in range(dataset_dim)]\n",
    "        for cluster in range(k):\n",
    "            randoms = [random.randint(min_value, max_value) for i in range(dataset_dim)]\n",
    "            old_centroids.append(zeros)\n",
    "            centroids.append(randoms)\n",
    "            delta_centroid_sum = delta_centroid_sum + dist_fun(zeros, randoms)\n",
    "        while delta_centroid_sum != 0:\n",
    "            for dataset in data:\n",
    "                cluster_distances = []\n",
    "                for cluster in range(k):\n",
    "                    cluster_distances.append(dist_fun(dataset, centroids[cluster]))\n",
    "                cluster_for_dataset.append(cluster_distances.index(min(cluster_distances)))\n",
    "            delta_centroid_sum = 0\n",
    "            for cluster in range(k):\n",
    "                cluster_members = []\n",
    "                for i in range(len(data)):\n",
    "                    if cluster == cluster_for_dataset[i]:\n",
    "                        cluster_members.append(data[i])\n",
    "                old_centroids[cluster] = centroids[cluster]\n",
    "                datapoint_means = [0 for i in range(dataset_dim)]\n",
    "                cluster_member_count = len(cluster_members)\n",
    "                for dataset in cluster_members:\n",
    "                    for i in range(len(dataset)):\n",
    "                        datapoint_means[i] = datapoint_means[i] + dataset[i]/cluster_member_count\n",
    "                centroids[cluster] = datapoint_means\n",
    "                clusters[cluster] = cluster_members\n",
    "                delta_centroid_sum = delta_centroid_sum + dist_fun(old_centroids[cluster], centroids[cluster])\n",
    "        return clusters, centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОЦЕНКА КЛАСТЕРИЗАЦИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alena\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:/Users/alena/Desktop/Data_Scientist/Z08/johnsnowlabs-food-nutrition-value-database/data_new.csv')\n",
    "df4 = df[['Desk3','cluster']]\n",
    "df4['cluster'] = df4['cluster'].str.split(' ').str[1]\n",
    "df4 = df4.sort_values(['cluster'])\n",
    "df4 = df4.drop_duplicates()\n",
    "\n",
    "i=0  \n",
    "sp2_ =[]\n",
    "for i in range(28):\n",
    "    str2_ = []\n",
    "    cd = df4[df4['cluster'] == str(int(i)+1)] \n",
    "    j = 0\n",
    "    for j in range(len(cd)):\n",
    "        str2_.append(str(cd.iloc[j]['Desk3']))\n",
    "    sp2_.append(str(str2_)[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/alena/Desktop/Data_Scientist/Z08/johnsnowlabs-food-nutrition-value-database/data_new.csv')\n",
    "df = df.sort_values(['Desk3'])\n",
    "ls_Names = df[\"Desk3\"].tolist()\n",
    "ls_Names = df[\"Desk3\"]\n",
    "ls_Names = list(OrderedDict.fromkeys(ls_Names))\n",
    "cc = pd.DataFrame(ls_Names)\n",
    "List = cc.values.tolist()\n",
    "List\n",
    "sp_ =[]\n",
    "str_ = []\n",
    "cl = clustering_Lev_kmeans\n",
    "def main():\n",
    "    data= List\n",
    "    \n",
    "    datapoint2num, num2datapoint = cl.create_dicts(data)\n",
    "    cl.convert_with_dictionary(data, datapoint2num)\n",
    "    clusters, centroids = cl.k_means(28, data, dtw_distance)\n",
    "    for i in range(28):\n",
    "        str_ = []\n",
    "        cl.convert_with_dictionary(clusters[i], num2datapoint)\n",
    "        for j in range(len(clusters[i])):\n",
    "            str_.append(str(clusters[i][j])[2:-2])\n",
    "        sp_.append(str(str_)[1:-1])\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>cluster_id_x</th>\n",
       "      <th>cluster_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>'пончики', 'открытый пирог', 'панировочные сух...</td>\n",
       "      <td>'андреа', 'апельсиновый сок', 'батончик из рис...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>'грибы белые', 'грибы устрицы', 'гриб', 'грибы...</td>\n",
       "      <td>'арбуз', 'бобер', 'бобы', 'вино', 'гвоздика', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>'чипсы', 'перекус', 'хумус', 'тамалес', 'чизер...</td>\n",
       "      <td>'агава', 'груша', 'датское тесто', 'желтохвост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>'сливки', 'обезжиренный йогурт', 'сметана', 'ф...</td>\n",
       "      <td>'абиюч', 'авокадо', 'базилик', 'бальзам груша ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>'эдамам', 'шелковица', 'хлопья', 'ячмень', 'яч...</td>\n",
       "      <td>'апельсиново-грейпфрутный сок', 'гуанабанский ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>'макароны', 'лазанья', 'рисовая лапша', 'кунжу...</td>\n",
       "      <td>'бамбуковые побеги', 'банановые чипсы', 'виног...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>'маргарин', 'фруктовые масла', 'китовий жир', ...</td>\n",
       "      <td>'болонья', 'грвы', 'каши', 'листья голени', 'м...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>'молоко шоколадное', 'молочные шейки', 'молоко...</td>\n",
       "      <td>'выпечка для тостов', 'душистый перец', 'жир и...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>'мороженое ванильное', 'лед', 'мороженое клубн...</td>\n",
       "      <td>'бедро индейки', 'брокколи', 'вокас', 'восточн...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>'говядина', 'телятина филейка', 'свиная колбас...</td>\n",
       "      <td>'агар', 'английский маффин', 'буррито', 'взбит...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>'рисовое молоко', 'энергетический напиток', 'п...</td>\n",
       "      <td>'агутук', 'ананасовый сок', 'апельсиновая корк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>'огурец', 'картофель', 'перец', 'оливки', 'ово...</td>\n",
       "      <td>'бекон индейки', 'зеленый чай', 'икра', 'капер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>'смесь орехов', 'кокос', 'орехи', 'буковые оре...</td>\n",
       "      <td>'блины', 'диджорно', 'козлобородник', 'кофейны...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>'ветчина из индейки', 'паштет', 'патэ', 'свини...</td>\n",
       "      <td>'абрикос', 'бротвурст', 'канпё', 'карибу', 'ла...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>'желатин', 'кардамон', 'подсластитель', 'подсл...</td>\n",
       "      <td>'васаби', 'вафли', 'виноград', 'датское печень...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>'замороженные новинки', 'линккод', 'питательна...</td>\n",
       "      <td>'алкогольный бэв', 'барабан', 'бублик', 'ванил...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>'птица', 'утка', 'рябчик', 'грудка индейки', '...</td>\n",
       "      <td>'ирландский мох', 'киви', 'кукурузный хлеб', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>'артишок', 'скумбрия', 'камбала', 'кальмар', '...</td>\n",
       "      <td>'айва', 'арахисовое масло', 'асерола', 'барани...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>'семечки', 'семена кунжута', 'льняное семя', '...</td>\n",
       "      <td>'белокопытник', 'брюссельская капуста', 'ветчи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>'соус', 'сиропы', 'горчица', 'сироп', 'кетчуп'...</td>\n",
       "      <td>'анчови', 'анчоус', 'банкет', 'бизон', 'гранат...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>'суп', 'луовый суп', 'куриный бульон', 'суп с ...</td>\n",
       "      <td>'апельсины', 'аррорут', 'буйвол', 'виноградный...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>'сыр творожный', 'сыр', 'сыр рокфор', 'сыр син...</td>\n",
       "      <td>'арахис', 'бамия', 'барбекю', 'бифало', 'бойзе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>'белокопытник', 'шелк', 'кресс', 'каперсы', 'р...</td>\n",
       "      <td>'баклажан', 'вино безалкогольное', 'выпечка дл...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>'келлог', 'фастфуд', 'бургер кинг', 'каши', 'к...</td>\n",
       "      <td>'абрикосовый нектар', 'верба', 'выпечка в тост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>'абрикос', 'тамаринд', 'тамарин', 'чайот', 'ды...</td>\n",
       "      <td>'арби', 'белка', 'буковые орехи', 'говядина фи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>'хлеб', 'хлеб без глютена', 'хлеб белый', 'хле...</td>\n",
       "      <td>'акула', 'ананас', 'артишок', 'барбара ди', 'б...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>'брюква', 'ежевика', 'смородина', 'изюм', 'бой...</td>\n",
       "      <td>'ванс', 'гарнир', 'голодный человек', 'грудка ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>'яйцо', 'яйцо перелиное', 'яйцо индейка', 'зам...</td>\n",
       "      <td>'антилопа', 'арахисовая мука', 'асцид', 'белуг...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    user_id                                       cluster_id_x  \\\n",
       "0         0  'пончики', 'открытый пирог', 'панировочные сух...   \n",
       "1         1  'грибы белые', 'грибы устрицы', 'гриб', 'грибы...   \n",
       "2         2  'чипсы', 'перекус', 'хумус', 'тамалес', 'чизер...   \n",
       "3         3  'сливки', 'обезжиренный йогурт', 'сметана', 'ф...   \n",
       "4         4  'эдамам', 'шелковица', 'хлопья', 'ячмень', 'яч...   \n",
       "5         5  'макароны', 'лазанья', 'рисовая лапша', 'кунжу...   \n",
       "6         6  'маргарин', 'фруктовые масла', 'китовий жир', ...   \n",
       "7         7  'молоко шоколадное', 'молочные шейки', 'молоко...   \n",
       "8         8  'мороженое ванильное', 'лед', 'мороженое клубн...   \n",
       "9         9  'говядина', 'телятина филейка', 'свиная колбас...   \n",
       "10       10  'рисовое молоко', 'энергетический напиток', 'п...   \n",
       "11       11  'огурец', 'картофель', 'перец', 'оливки', 'ово...   \n",
       "12       12  'смесь орехов', 'кокос', 'орехи', 'буковые оре...   \n",
       "13       13  'ветчина из индейки', 'паштет', 'патэ', 'свини...   \n",
       "14       14  'желатин', 'кардамон', 'подсластитель', 'подсл...   \n",
       "15       15  'замороженные новинки', 'линккод', 'питательна...   \n",
       "16       16  'птица', 'утка', 'рябчик', 'грудка индейки', '...   \n",
       "17       17  'артишок', 'скумбрия', 'камбала', 'кальмар', '...   \n",
       "18       18  'семечки', 'семена кунжута', 'льняное семя', '...   \n",
       "19       19  'соус', 'сиропы', 'горчица', 'сироп', 'кетчуп'...   \n",
       "20       20  'суп', 'луовый суп', 'куриный бульон', 'суп с ...   \n",
       "21       21  'сыр творожный', 'сыр', 'сыр рокфор', 'сыр син...   \n",
       "22       22  'белокопытник', 'шелк', 'кресс', 'каперсы', 'р...   \n",
       "23       23  'келлог', 'фастфуд', 'бургер кинг', 'каши', 'к...   \n",
       "24       24  'абрикос', 'тамаринд', 'тамарин', 'чайот', 'ды...   \n",
       "25       25  'хлеб', 'хлеб без глютена', 'хлеб белый', 'хле...   \n",
       "26       26  'брюква', 'ежевика', 'смородина', 'изюм', 'бой...   \n",
       "27       27  'яйцо', 'яйцо перелиное', 'яйцо индейка', 'зам...   \n",
       "\n",
       "                                         cluster_id_y  \n",
       "0   'андреа', 'апельсиновый сок', 'батончик из рис...  \n",
       "1   'арбуз', 'бобер', 'бобы', 'вино', 'гвоздика', ...  \n",
       "2   'агава', 'груша', 'датское тесто', 'желтохвост...  \n",
       "3   'абиюч', 'авокадо', 'базилик', 'бальзам груша ...  \n",
       "4   'апельсиново-грейпфрутный сок', 'гуанабанский ...  \n",
       "5   'бамбуковые побеги', 'банановые чипсы', 'виног...  \n",
       "6   'болонья', 'грвы', 'каши', 'листья голени', 'м...  \n",
       "7   'выпечка для тостов', 'душистый перец', 'жир и...  \n",
       "8   'бедро индейки', 'брокколи', 'вокас', 'восточн...  \n",
       "9   'агар', 'английский маффин', 'буррито', 'взбит...  \n",
       "10  'агутук', 'ананасовый сок', 'апельсиновая корк...  \n",
       "11  'бекон индейки', 'зеленый чай', 'икра', 'капер...  \n",
       "12  'блины', 'диджорно', 'козлобородник', 'кофейны...  \n",
       "13  'абрикос', 'бротвурст', 'канпё', 'карибу', 'ла...  \n",
       "14  'васаби', 'вафли', 'виноград', 'датское печень...  \n",
       "15  'алкогольный бэв', 'барабан', 'бублик', 'ванил...  \n",
       "16  'ирландский мох', 'киви', 'кукурузный хлеб', '...  \n",
       "17  'айва', 'арахисовое масло', 'асерола', 'барани...  \n",
       "18  'белокопытник', 'брюссельская капуста', 'ветчи...  \n",
       "19  'анчови', 'анчоус', 'банкет', 'бизон', 'гранат...  \n",
       "20  'апельсины', 'аррорут', 'буйвол', 'виноградный...  \n",
       "21  'арахис', 'бамия', 'барбекю', 'бифало', 'бойзе...  \n",
       "22  'баклажан', 'вино безалкогольное', 'выпечка дл...  \n",
       "23  'абрикосовый нектар', 'верба', 'выпечка в тост...  \n",
       "24  'арби', 'белка', 'буковые орехи', 'говядина фи...  \n",
       "25  'акула', 'ананас', 'артишок', 'барбара ди', 'б...  \n",
       "26  'ванс', 'гарнир', 'голодный человек', 'грудка ...  \n",
       "27  'антилопа', 'арахисовая мука', 'асцид', 'белуг...  "
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ID = range(28)\n",
    "dd = {'user_id':ID, 'cluster_id_x':sp2_, 'cluster_id_y':sp_}\n",
    "dd2 = pd.DataFrame(dd)\n",
    "dd2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def BCubedMetrics(df):\n",
    "    '''\n",
    "    Функция нужна для расчета BCubed метрик для кластеризации.\n",
    "    Вдохновение взято отсюда: https://habr.com/ru/company/yandex/blog/500742/\n",
    "    Основополагающая статья: http://nlp.uned.es/docs/amigo2007a.pdf\n",
    "\n",
    "    Функция принимает на вход pd.DataFrame(), состоящий из трех столбцов: id, cluster_id_true, cluster_id_computed\n",
    "    Названя столбцов не имеют значения, но важен их порядок\n",
    "\n",
    "    Также важно, что один id принадлежит одному кластеру\n",
    "    '''\n",
    "\n",
    "    # Переименуем колонки, чтобы проще было в дальнейшем к ним обращаться\n",
    "    df.columns = ['user_id', 'cluster_id_x', 'cluster_id_y']\n",
    "\n",
    "    # Найдем размеры кластеров\n",
    "    true_cluster_size = df.loc[:, ['user_id', 'cluster_id_x']].groupby('cluster_id_x').count().reset_index(). \\\n",
    "        rename(columns={'user_id': 'cluster_id_x_size'})\n",
    "    computed_cluster_size = df.loc[:, ['user_id', 'cluster_id_y']].groupby('cluster_id_y').count().reset_index(). \\\n",
    "        rename(columns={'user_id': 'cluster_id_y_size'})\n",
    "\n",
    "    # Присоединим полученные размеры к изначальным данным\n",
    "    df = pd.merge(df, true_cluster_size, how='left', on='cluster_id_x')\n",
    "    df = pd.merge(df, computed_cluster_size, how='left', on='cluster_id_y')\n",
    "\n",
    "    # Для каждого кластера составим лист id, входящих в него\n",
    "    true_clusters_elements = df.loc[:, ['user_id', 'cluster_id_x']].groupby('cluster_id_x')['user_id']. \\\n",
    "        apply(list).reset_index().rename(columns={'user_id': 'cluster_id_x_elements'})\n",
    "    computed_clusters_elements = df.loc[:, ['user_id', 'cluster_id_y']].groupby('cluster_id_y')['user_id']. \\\n",
    "        apply(list).reset_index().rename(columns={'user_id': 'cluster_id_y_elements'})\n",
    "\n",
    "    # Присоединим\n",
    "    df = pd.merge(df, true_clusters_elements, how='left', on='cluster_id_x')\n",
    "    df = pd.merge(df, computed_clusters_elements, how='left', on='cluster_id_y')\n",
    "\n",
    "    # А теперь посчитаем поэлементную длину пересечения кластеров\n",
    "    df = pd.concat([df, df.apply(lambda x: len(set(x['cluster_id_x_elements']) & set(x['cluster_id_y_elements'])),\n",
    "                                 axis=1)],\n",
    "                   axis=1)\n",
    "\n",
    "    # Переименуем эту колонку\n",
    "    df.rename(columns={0: 'intersection_size'}, inplace=True)\n",
    "\n",
    "    # Посчитаем поэлементные метрики\n",
    "    df['BCP'] = df['intersection_size'] / df['cluster_id_y_size']\n",
    "    df['BCR'] = df['intersection_size'] / df['cluster_id_x_size']\n",
    "\n",
    "    # Посчитаем итоговые метрики\n",
    "    result = np.mean(df[['cluster_id_x', 'BCP', 'BCR']].groupby('cluster_id_x').mean().reset_index()[['BCP', 'BCR']])\n",
    "    result['BCF1'] = (2 * result['BCP'] * result['BCR']) / (result['BCP'] + result['BCR'])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BCP     1.0\n",
       "BCR     1.0\n",
       "BCF1    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCubedMetrics(dd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "МОДЕЛЬ БЛИЖАЙШЕГО СОСЕДА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "import pandas as pandas\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import operator\n",
    "import numpy as np\n",
    "import scipy.optimize as optimize\n",
    "import math\n",
    "\n",
    "def euclidianDistance(instance1, instance2, length):\n",
    "    distance = 0\n",
    "    for x in range(length):\n",
    "        distance = distance + pow((instance1[x] - instance2[x]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def getNeighborsKnn(trainSet, instance, k):\n",
    "    distances = []\n",
    "    length = len(trainSet[0]) - 1\n",
    "    for x in range(len(trainSet)):\n",
    "        dist = euclidianDistance(instance, trainSet[x], length)\n",
    "        distances.append((trainSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors\n",
    "\n",
    "def getDistances(neighbors, y):\n",
    "    distances = []\n",
    "    for x in neighbors:\n",
    "        distance = euclidianDistance(y, x, len(neighbors[0]))\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "def getRelativeDistances(distances):\n",
    "    relativeDistances = []\n",
    "    for x in distances:\n",
    "        if min(distances) == 0:\n",
    "            relativeDistances.append(0)\n",
    "        else:\n",
    "            relativeDistance = (x - min(distances)) / min(distances)\n",
    "            relativeDistances.append(relativeDistance)\n",
    "    return relativeDistances\n",
    "\n",
    "def getDistancePenalizingFactors(relativeDistances, n):\n",
    "    penalizingFactors = []\n",
    "    for x in relativeDistances:\n",
    "        penalizingFactor = math.exp((-n) * x)\n",
    "        penalizingFactors.append(penalizingFactor)\n",
    "    return penalizingFactors\n",
    "\n",
    "def minimization(resultPredicted, trueResult, penalizingFactors, n_classes):\n",
    "\n",
    "    def f(x):\n",
    "        soma = 0\n",
    "        for i in range(len(resultPredicted)):\n",
    "            bt = np.reshape(x, (n_classes,n_classes)).transpose()\n",
    "            rp = np.reshape(np.array(resultPredicted[i]), (n_classes, 1))\n",
    "            tr = np.reshape(np.array(trueResult[i]), (n_classes, 1))\n",
    "            soma = soma + (penalizingFactors[i]*(distance.euclidean(np.dot(bt, rp), tr)))\n",
    "        return soma\n",
    "\n",
    "    initial_guess = np.array(np.identity(n_classes))\n",
    "    dimension = initial_guess.shape\n",
    "    bounds = [(0, 1)]*(n_classes*n_classes)\n",
    "\n",
    "    eq_cons = ({'type': 'eq',\n",
    "               'fun': lambda x: np.array([x[0] + x[1] + x[2] - 1,\n",
    "                                          x[3] + x[4] + x[5] - 1,\n",
    "                                          x[6] + x[7] + x[8] - 1])})\n",
    "\n",
    "    result = optimize.minimize(f, initial_guess, method='slsqp', constraints=eq_cons, bounds=bounds)\n",
    "    return (np.reshape(np.array(result.x), (n_classes,n_classes)))\n",
    "\n",
    "def correctClassification(b, y, u):\n",
    "    return (y*(np.dot((np.reshape(b, (len(u[0]),len(u[0]))).transpose()),(u.transpose())))) + ((1 - y)*(u.transpose()))\n",
    "\n",
    "def main():\n",
    "    graphResultBefore = []\n",
    "    graphResultAfter = []\n",
    "    simplefilter(action='ignore', category=FutureWarning)\n",
    "           \n",
    "    data = pandas.read_csv('C:/Users/alena/Desktop/Data_Scientist/Z08/johnsnowlabs-food-nutrition-value-database/data_new.csv')\n",
    "   \n",
    "    data = data.drop('Short_Description_ru', axis=1)\n",
    "    data = data.drop('Short_Description', axis=1)\n",
    "    data = data.drop('Gram_Weight_Descritpion_1', axis=1)\n",
    "    data = data.drop('Gram_Weight_Description_2', axis=1)\n",
    "    \n",
    "    \n",
    "    data2 = data.loc[data['Desk3'] == key] \n",
    "    classter = data2.iloc[0]['cluster']\n",
    "    \n",
    "    data = data.loc[data['cluster'] == classter] \n",
    "    data = data.drop('cluster', axis=1)\n",
    "     \n",
    "    X_train = data.loc[data['Desk3'] != key] \n",
    "    X_train = X_train.drop('Desk3', axis=1)\n",
    "    \n",
    "    X_test = data.loc[data['Desk3'] == key] \n",
    "    X_test = X_test.drop('Desk3', axis=1)\n",
    "    \n",
    "    y_train = data.loc[data['Desk3'] != key] \n",
    "    y_train = y_train['Desk3']\n",
    "    \n",
    "    y_test = data.loc[data['Desk3'] == key] \n",
    "    y_test = y_test['Desk3']\n",
    "    \n",
    "    cl = data['Desk3']\n",
    "    cl = cl.drop_duplicates()\n",
    "    l_cl = len(cl)\n",
    "    classes = list(range(1, l_cl +1 ))\n",
    "\n",
    "    yParameter = [0.1]\n",
    "    for i in yParameter:\n",
    "        classifier = GaussianNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        pred = classifier.predict(X_test)\n",
    "\n",
    "        accuracyBefore = metrics.accuracy_score(y_test, pred)\n",
    "        graphResultBefore.append(accuracyBefore)\n",
    "\n",
    "        matBefore = confusion_matrix(pred, y_test)\n",
    "\n",
    "        k = 5\n",
    "        counter = 0\n",
    "        nParameter = 5\n",
    "        resultCorrected = []\n",
    "        for a in range(len(X_test)):\n",
    "            neighbors = getNeighborsKnn(X_train.values, X_test.values[a], k)\n",
    "            distances = getDistances(neighbors, X_test.values[a])\n",
    "            relativeDistances = getRelativeDistances(distances)\n",
    "            penalizingFactors = getDistancePenalizingFactors(relativeDistances, nParameter)\n",
    "            predNeighborsVector = classifier.predict_proba(neighbors)\n",
    "\n",
    "            trueResult = []\n",
    "            for v in range(len(neighbors)):\n",
    "                for l in range(len(X_train.values)):\n",
    "                    if all(neighbors[v] == X_train.values[l]):\n",
    "                        trueResult.append(y_train.values[l])\n",
    "\n",
    "            trueResultVector = []\n",
    "            for true in trueResult:\n",
    "                aux = []\n",
    "                if true == classes[0]: \n",
    "                    aux = np.zeros(len(classes))\n",
    "                    aux[0] = 1.0\n",
    "                if true == classes[1]: \n",
    "                    aux = np.zeros(len(classes))\n",
    "                    aux[1] = 1.0\n",
    "                if true == classes[2]: \n",
    "                    aux = np.zeros(len(classes))\n",
    "                    aux[2] = 1.0\n",
    "                trueResultVector.append(aux)\n",
    "            u = classifier.predict_proba([X_test.values[a]])\n",
    "            uClass = classifier.predict([X_test.values[a]])\n",
    "\n",
    "            \n",
    "    print(uClass)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['сливки']\n"
     ]
    }
   ],
   "source": [
    "key = 'творог'\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ЗАПИСЬ АНАЛОГОВ ИЗ МОДЕЛИ В ФАЙЛ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.read_csv('C:/Users/alena/Desktop/Data_Scientist/Z08/johnsnowlabs-food-nutrition-value-database/data_new.csv')\n",
    "data = data[\"Desk3\"]\n",
    "data = data.drop_duplicates()\n",
    "ll = len(data)\n",
    "ID = range(len(data))\n",
    "dd_ = {'ID':ID, 'product':data, 'similar':ID}\n",
    "dd2_ = pandas.DataFrame(dd_)\n",
    "dd2_ = dd2_.set_index('ID')\n",
    "dd2_\n",
    "\n",
    "for i in ID:\n",
    "    key = dd2_.loc[i,'product']\n",
    "    uClass = main()\n",
    "    dd2_.loc[i,'similar']  = uClass\n",
    "    \n",
    "dd2_.to_csv('C:/Users/alena/Desktop/Data_Scientist/Z08/johnsnowlabs-food-nutrition-value-database/similar.csv', index=False)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ПОИСК ПОХОЖЕГО ПРОДУКТА ИЗ ФАЙЛА"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('C:/Users/alena/Desktop/Data_Scientist/Z08/johnsnowlabs-food-nutrition-value-database/similar.csv')\n",
    "key = input(\"Введите продукт: \")\n",
    "\n",
    "data2 = data.loc[data['product'] == key]\n",
    "if len(data2) > 0:\n",
    "    sim = data2.iloc[0]['similar']\n",
    "    print(\"Похожий продукт: \", sim)\n",
    "if len(data2) == 0:\n",
    "    data3 = data.loc[data['product'].str.contains(key)]\n",
    "    bn = data3['product']\n",
    "    if len(bn) == 0:\n",
    "        key = key[:3]\n",
    "        data5 = data.loc[data['product'].str.contains(key)]\n",
    "        bn5 = data5['product']\n",
    "        if len(bn5) > 0:\n",
    "            print (\"Возможно вы имели ввиду: \")\n",
    "            print (\" \")\n",
    "            for i in range(len(bn5)):\n",
    "                print(bn5.iloc[i])\n",
    "            prod = input(\"Введите продукт из списка : \")\n",
    "            data4 = data.loc[data['product'] == prod]\n",
    "            if len(data4) > 0:\n",
    "                sim = data4.iloc[0]['similar']\n",
    "                print(\"Похожий продукт: \", sim)\n",
    "            else:\n",
    "                print (\"Не знаю такой продукт :( \")\n",
    "    if len(bn) > 0:\n",
    "        print (\"Возможно вы имели ввиду: \")\n",
    "        print (\" \")\n",
    "        for i in range(len(bn)):\n",
    "            print(bn.iloc[i])\n",
    "        prod = input(\"Введите продукт из списка : \")\n",
    "        data4 = data.loc[data['product'] == prod]\n",
    "        if len(data4) > 0:\n",
    "            sim = data4.iloc[0]['similar']\n",
    "            print(\"Похожий продукт: \", sim)\n",
    "        else:\n",
    "            print (\"Не знаю такой продукт :( \")\n",
    "    else: (\"Не знаю такой продукт :( \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>завтрак</td>\n",
       "      <td>закуска</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>абиюч</td>\n",
       "      <td>замороженные новинки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>абрикос</td>\n",
       "      <td>чернослив</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>абрикосовый нектар</td>\n",
       "      <td>апельсиновый сок</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>авокадо</td>\n",
       "      <td>перец</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1091</td>\n",
       "      <td>яхтверст</td>\n",
       "      <td>обед</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1092</td>\n",
       "      <td>ячменная мука</td>\n",
       "      <td>ячмень</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1093</td>\n",
       "      <td>ячменный солод</td>\n",
       "      <td>пшеница</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1094</td>\n",
       "      <td>ячмень</td>\n",
       "      <td>пшеница</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1095</td>\n",
       "      <td>творог</td>\n",
       "      <td>сливки</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1096 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 product               similar\n",
       "0                завтрак               закуска\n",
       "1                  абиюч  замороженные новинки\n",
       "2                абрикос             чернослив\n",
       "3     абрикосовый нектар      апельсиновый сок\n",
       "4                авокадо                 перец\n",
       "...                  ...                   ...\n",
       "1091            яхтверст                  обед\n",
       "1092       ячменная мука                ячмень\n",
       "1093      ячменный солод               пшеница\n",
       "1094              ячмень               пшеница\n",
       "1095              творог                сливки\n",
       "\n",
       "[1096 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('C:/Users/alena/Desktop/Data_Scientist/Z08/johnsnowlabs-food-nutrition-value-database/similar22.csv',sep =';')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('C:/Users/alena/Desktop/Data_Scientist/Z08/johnsnowlabs-food-nutrition-value-database/similar.csv', index=False)  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
